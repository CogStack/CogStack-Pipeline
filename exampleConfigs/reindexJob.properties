# EXAMPLE CONFIG FOR reindex Job 
#####Elasticsearch CONFIGURATION####
#ES cluster name
elasticsearch.cluster.name = elasticsearch
#ES cluster IP/hostname
elasticsearch.cluster.host =  localhost
#ES cluster transport port
elasticsearch.cluster.port = 9300
#ES the shield plugin (commercial)
elasticsearch.shield.enabled = false
#Shield username/password
elasticsearch.shield.user = <user>:<password>
#ES keystore for ssl
elasticsearch.shield.ssl.keystore.path = /home/rich/elk/ssh-keystores/tempnode/tempnode.jks
#ES keystore password
elasticsearch.shield.ssl.keystore.password = <password>
#ES Truststore (see Shield docs)
elasticsearch.shield.ssl.truststore.path = /home/rich/elk/ssh-keystores/tempnode/tempnode.jks
#ES Truststore password
elasticsearch.shield.ssl.truststore.password = <password>
#use encryption on transport layer
elasticsearch.shield.transport.ssl = true

##General ES options
#load data into this index
elasticsearch.index.name = test_index2
#load data into this type
elasticsearch.type = test_type
#Allow this many ms for cluster response
elasticsearch.response.timeout = 1000000
#If the input SQL query returns columns with these labels, ignore them
elasticsearch.excludeFromIndexing = binaryContent,primaryKeyFieldName
#specify the JODA date pattern that is compatible with the elasticsearch dynamic file mapping for dates (see ES docs on dates)
datePatternForES = yyyy-MM-dd'T'HH:mm:ss.SSS
#####REINDEX CONFIGURATION####
#if true, reindex a column of jsons generated from a previous job
reindex = true

#select column name of jsons
reindexField = sometext
#####JMS CONFIGURATION####
##Only required if using remote partitioning

#IP of JMS server
jmsIP = tcp://172.17.0.3:61616?jms.prefetchPolicy.all=1
jmsUsername = admin
jmsPassword = your_password
##timeout to prevent a hung client
closeTimeout = 100000

#name of request channel (should be job unique)
requestQueueName = basicReqChannel
#name of reply channel (should be job unique)
replyQueueName = basicReplyQueue
#####JOB AND STEP CONFIGURATION####
# commit interval in step - process this many rows before committing results
chunkSize = 50
#number of exceptions that can be thrown before job fails.
skipLimit = 5

#Asynchonous TaskExecutor Thread pool size - for multithreading partitions
concurrencyLimit = 16

# DB column label mapping for metadata
srcTableName = srctablename
srcColumnFieldName = srcColumnFieldName
primaryKeyFieldName = primaryKeyFieldName
primaryKeyFieldValue = primaryKeyFieldValue
timeStamp = updateTime

#job should complete before this many ms or it will be listed as a failure.
jobTimeout = 10000000

#globally unique job name
jobName = aJob

#since some JDBC drivers don't support socket timeouts, they can't detect network failures.
#This workaround allows us to specify a global socket timeout for the JVM without diving into the OS socket configuration.
#However, the downside is that all sockets are affected in the JVM, so may not always be appropriate to set this. Comment out to
#not use this global setting
globalSocketTimeout = 30000

#number of partitions to generate
gridSize = 3

#ms for partition handler to complete partitioning before an exception is thrown
partitionHandlerTimeout = 10000000

#name of timestamp colum used for checking for new data
timeStampColumnNameToPersistInJobRepository = updateTime

#ms to scan forward for new data
#processingPeriod = 345600000

#if configured, overrides the grid size and sets the max number of rows per partition.
#Warning - if used, can result in large numbers of partitions per job

#maxPartitionSize = 1000

#if configured, queries the source database to ensure that each partition has at least 1 row of data.
#Helpful to avoid masses of empty partitions when connecting to a database with non-sequestial primary keys. However, also
#requires a count query to be performed, which might not always be desirable

#checkForEmptyPartitions = false
#JTDS now obsolete due to JDBC4.0
### SQL SERVER TARGET DB CONFIGURATIONS
#target.JdbcPath      = jdbc:jtds:sqlserver://192.168.1.7:1433/minicogs
#target.Driver        = net.sourceforge.jtds.jdbc.Driver
#target.username      = sqlserver
#target.password      = mysecretpassword
#target.connectionValidationQuery = SELECT CASE WHEN DATABASEPROPERTYEX('minicogs', 'Status') = 'ONLINE' THEN 1 END
#
### SOURCE TARGET DB CONFIGURATIONS
#source.JdbcPath      = jdbc:jtds:sqlserver://192.168.1.7:1433/minicogs
#source.Driver        = net.sourceforge.jtds.jdbc.Driver
#source.username      = sqlserver
#source.password      = mysecretpassword
#source.connectionValidationQuery = SELECT CASE WHEN DATABASEPROPERTYEX('minicogs', 'Status') = 'ONLINE' THEN 1 END

## SQL SERVER TARGET DB CONFIGURATIONS
target.JdbcPath      = jdbc:sqlserver://192.168.1.110:1433;DatabaseName=minicogs
target.Driver        = com.microsoft.sqlserver.jdbc.SQLServerDriver
target.username      = sqlserver
target.password      = mysecretpassword
target.idleTimeout   = 30000
target.maxLifetime   = 60000

## SOURCE TARGET DB CONFIGURATIONS
source.JdbcPath      = jdbc:sqlserver://192.168.1.110:1433;DatabaseName=minicogs
source.Driver        = com.microsoft.sqlserver.jdbc.SQLServerDriver
source.username      = sqlserver
source.password      = mysecretpassword
source.idleTimeout   = 30000
source.maxLifetime   = 60000

#JobRepo DB config
jobRepository.JdbcPath      = jdbc:sqlserver://192.168.1.110:1433;DatabaseName=jobrepo
jobRepository.Driver        = com.microsoft.sqlserver.jdbc.SQLServerDriver
jobRepository.username      = sqlserver
jobRepository.password      = mysecretpassword
jobRepository.idleTimeout   = 30000
jobRepository.maxLifetime   = 60000

datePatternForScheduling = yyyy-MM-dd HH:mm:ss.S
dbmsToJavaSqlTimestampType = DATETIME




target.Sql = INSERT INTO minicogs.dbo.tblOutputDocs (srcColumnFieldName, srcTableName, primaryKeyFieldName, primaryKeyFieldValue, updateTime, output) VALUES (:srcColumnFieldName, :srcTableName, :primaryKeyFieldName, CAST ( :primaryKeyFieldValue AS integer), :timeStamp, :outputData)

## paging item reader configuration
source.selectClause = SELECT *
source.sortKey = primaryKeyFieldValue
##paging item reader
source.pageSize = 2
source.fromClause = FROM minicogs.dbo.tblinputDocs

partitionerPreFieldsSQL = TOP 100 PERCENT

#for partitioning
#if the step target table has a different alias to the partition table
columnToProcess = primaryKeyFieldValue
#this is the table containing the primary keys and timestamps
tableToPartition = minicogs.dbo.tblinputDocs
pkColumnNameToPartition = primaryKeyFieldValue

#for DBLineFixer - concatenate text from multiple database rows
# primary key of original document
lf.documentKeyName = primaryKeyFieldValue
# primary key from table with multi row documents
lf.lineKeyName = line_id
# text content from table with multi row documents
lf.lineContents = line_text
#source table of multi row documents
lf.srcTableName = minicogs.dbo.tblDocLines
# fieldname for lineFixer output
dbLineFixerFieldName = lineFixer
#####Scheduler CONFIGURATION####
#if true, run a new job after the last one has finished - new jobs will continute to be created indefinitely
useScheduling = true
## if above is true, new jobs will be created according to this CRON style schedule
scheduler.rate = */5 * * * * *

#if useTimeStampBasedScheduling is true, process this number of milliseconds from last successful job/first timestamp/start date,
#depending on configuration and status of the JobRepository. For instance, last timestamp in job1 is t0. job2 will then look for
#new data where t0 < timestamp <= t0+processingPeriod
processingPeriod = 77760000000

spring.profiles.active=basic,localPartitioning,jdbc_in,elasticsearch,primaryKeyAndTimeStampPartition